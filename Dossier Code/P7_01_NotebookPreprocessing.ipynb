{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d309b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4796d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8337541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, y):\n",
    "    pca = PCA(n_components=2)\n",
    "    X = pca.fit_transform(X)\n",
    "    plot_2d_space(X, y, 'dataset (2 PCA components)')\n",
    "\n",
    "# 2-dimensional plot function, plot_2d_space, to see the data distribution:           \n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    # Data display\n",
    "    colors = ['#00FF00', '#FF0000']\n",
    "    for l, c in zip(np.unique(y), colors):\n",
    "        plt.scatter(X[y == l, 0],\n",
    "                    X[y == l, 1],\n",
    "                    c=c, label=l)\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f681c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Application Train\" shape : (307511, 122)\n",
      "\"Bureau\" shape : (1716428, 17)\n",
      "\"Bureau Balance\" shape : (27299925, 3)\n",
      "\"Previous Application\" shape : (1670214, 37)\n",
      "\"POS_CASH Balance\" shape : (10001358, 8)\n",
      "\"Installments Payments\" shape : (13605401, 8)\n",
      "\"Credit Card Balance\" shape : (3840312, 23)\n"
     ]
    }
   ],
   "source": [
    "# Importation des jeux de données\n",
    "path = '../Données/'\n",
    "\n",
    "train_df = pd.read_csv(path + 'application_train.csv')\n",
    "print('\"Application Train\" shape :', train_df.shape)\n",
    "df_bureau = pd.read_csv(path + 'bureau.csv')\n",
    "print('\"Bureau\" shape :', df_bureau.shape)\n",
    "df_bureau_balance = pd.read_csv(path + 'bureau_balance.csv')\n",
    "print('\"Bureau Balance\" shape :', df_bureau_balance.shape)\n",
    "df_previous = pd.read_csv(path + 'previous_application.csv')\n",
    "print('\"Previous Application\" shape :', df_previous.shape)\n",
    "df_pos_cash = pd.read_csv(path + 'POS_CASH_balance.csv')\n",
    "print('\"POS_CASH Balance\" shape :', df_pos_cash.shape)\n",
    "df_installments = pd.read_csv(path + 'installments_payments.csv')\n",
    "print('\"Installments Payments\" shape :', df_installments.shape)\n",
    "df_credit_card = pd.read_csv(path + 'credit_card_balance.csv')\n",
    "print('\"Credit Card Balance\" shape :', df_credit_card.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfa3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Application_Train\" shape: (307511, 122)\n",
      "\"Application_Train\" final shape: (252133, 247)\n",
      "Process application_train - done in 2s\n"
     ]
    }
   ],
   "source": [
    "# Preprocess application_train.csv\n",
    "with timer(\"Process application_train\"):\n",
    "    nan_as_category = False\n",
    "    df_applications = train_df\n",
    "    print('\"Application_Train\" shape:', df_applications.shape)\n",
    "    del train_df    \n",
    "    \n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    # df_applications = df_applications[df_applications['CODE_GENDER'] != 'XNA']\n",
    "    df_applications = df_applications[df_applications['CODE_GENDER'] != 'XNA']\n",
    "   \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df_applications[bin_feature], uniques = pd.factorize(df_applications[bin_feature])\n",
    "\n",
    "    # Categorical features with One-Hot encode\n",
    "    df_applications, cat_cols = one_hot_encoder(df_applications, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df_applications = df_applications[df_applications['DAYS_EMPLOYED']!= 365243]\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    df_applications['DAYS_EMPLOYED_PERC'] = df_applications['DAYS_EMPLOYED'] / df_applications['DAYS_BIRTH']\n",
    "    df_applications['INCOME_CREDIT_PERC'] = df_applications['AMT_INCOME_TOTAL'] / df_applications['AMT_CREDIT']\n",
    "    df_applications['INCOME_PER_PERSON'] = df_applications['AMT_INCOME_TOTAL'] / df_applications['CNT_FAM_MEMBERS']\n",
    "    df_applications['ANNUITY_INCOME_PERC'] = df_applications['AMT_ANNUITY'] / df_applications['AMT_INCOME_TOTAL']\n",
    "    df_applications['PAYMENT_RATE'] = df_applications['AMT_ANNUITY'] / df_applications['AMT_CREDIT']\n",
    "    print('\"Application_Train\" final shape:', df_applications.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380e14a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Bureau\" shape: (1716428, 17)\n",
      "\"Bureau Balance\" shape: (27299925, 3)\n",
      "\"Bureau/Bureau Balance\" final shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 15s\n"
     ]
    }
   ],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "with timer(\"Process bureau and bureau_balance\"):\n",
    "    nan_as_category = True\n",
    "    print('\"Bureau\" shape:', df_bureau.shape)\n",
    "    print('\"Bureau Balance\" shape:', df_bureau_balance.shape)\n",
    "\n",
    "    df_bureau_balance, bb_cat = one_hot_encoder(df_bureau_balance, nan_as_category)\n",
    "    df_bureau, bureau_cat = one_hot_encoder(df_bureau, nan_as_category)\n",
    "\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size', 'mean']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    # Status of Credit Bureau loan during the month\n",
    "    bb_agg = df_bureau_balance.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    df_bureau = df_bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    del df_bureau_balance, bb_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    df_bureau_agg = df_bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    df_bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in df_bureau_agg.columns.tolist()])\n",
    "    del  bureau_cat, bb_cat\n",
    "\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = df_bureau[df_bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    df_bureau_agg = df_bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = df_bureau[df_bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    df_bureau_agg = df_bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, df_bureau\n",
    "    gc.collect()\n",
    "\n",
    "    print('\"Bureau/Bureau Balance\" final shape:', df_bureau_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f18e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Previous applications\" shape: (1670214, 37)\n",
      "\"Previous applications\" final shape: (201759, 249)\n",
      "Process previous_applications - done in 12s\n"
     ]
    }
   ],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "with timer(\"Process previous_applications\"):\n",
    "    nan_as_category = True\n",
    "    print('\"Previous applications\" shape:', df_previous.shape)\n",
    "    df_previous, cat_cols = one_hot_encoder(df_previous, nan_as_category=True)\n",
    "\n",
    "    # Days 365.243 values -> nan\n",
    "    df_previous = df_previous[df_previous['DAYS_FIRST_DRAWING'] != 365243]\n",
    "    df_previous = df_previous[df_previous['DAYS_FIRST_DUE'] != 365243]\n",
    "    df_previous = df_previous[df_previous['DAYS_LAST_DUE_1ST_VERSION'] != 365243]\n",
    "    df_previous = df_previous[df_previous['DAYS_LAST_DUE'] != 365243]\n",
    "    df_previous = df_previous[df_previous['DAYS_TERMINATION'] != 365243]\n",
    "    \n",
    "    # Add feature: value ask / value received percentage\n",
    "    df_previous['APP_CREDIT_PERC'] = df_previous['AMT_APPLICATION'] / df_previous['AMT_CREDIT']  \n",
    "\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "\n",
    "    df_previous_agg = df_previous.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    df_previous_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in df_previous_agg.columns.tolist()])\n",
    "\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = df_previous[df_previous['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    df_previous_agg = df_previous_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    del approved, approved_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = df_previous[df_previous['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    df_previous_agg = df_previous_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del df_previous, refused, refused_agg\n",
    "    gc.collect()\n",
    "\n",
    "    print('\"Previous applications\" final shape:', df_previous_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa08761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pos-Cash\" shape: (10001358, 8)\n",
      "\"Pos-Cash\" final shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 8s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Process POS-CASH balance\"):\n",
    "    nan_as_category = True\n",
    "    print('\"Pos-Cash\" shape:', df_pos_cash.shape) \n",
    "    df_pos_cash, cat_cols = one_hot_encoder(df_pos_cash, nan_as_category=True)\n",
    "\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "\n",
    "    pos_agg = df_pos_cash.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = df_pos_cash.groupby('SK_ID_CURR').size()\n",
    "    del df_pos_cash\n",
    "    gc.collect()\n",
    "\n",
    "    print('\"Pos-Cash\" final shape:', pos_agg.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fd7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Installments Payments\" shape: (13605401, 8)\n",
      "\"Installments Payments\" final shape: (339587, 26)\n",
      "Process installments payments - done in 28s\n"
     ]
    }
   ],
   "source": [
    "# Preprocess installments_payments.csv\n",
    "with timer(\"Process installments payments\"):\n",
    "    nan_as_category = True\n",
    "    print('\"Installments Payments\" shape:', df_installments.shape)\n",
    "    df_installments, cat_cols = one_hot_encoder(df_installments, nan_as_category=True)\n",
    "\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    df_installments['PAYMENT_PERC'] = df_installments['AMT_PAYMENT'] / df_installments['AMT_INSTALMENT']\n",
    "    df_installments['PAYMENT_DIFF'] = df_installments['AMT_INSTALMENT'] - df_installments['AMT_PAYMENT']\n",
    "\n",
    "    # Days past due and days before due (no negative values)\n",
    "    df_installments['DPD'] = df_installments['DAYS_ENTRY_PAYMENT'] - df_installments['DAYS_INSTALMENT']\n",
    "    df_installments['DBD'] = df_installments['DAYS_INSTALMENT'] - df_installments['DAYS_ENTRY_PAYMENT']\n",
    "    df_installments['DPD'] = df_installments['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    df_installments['DBD'] = df_installments['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = df_installments.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = df_installments.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    del df_installments\n",
    "    gc.collect()\n",
    "\n",
    "    print('\"Installments Payments\" final shape:', ins_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e743822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Credit Card Balance\" shape: (3840312, 23)\n",
      "\"Credit Card Balance\" final shape: (103558, 141)\n",
      "Process credit card balance - done in 10s\n"
     ]
    }
   ],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "with timer(\"Process credit card balance\"):\n",
    "    nan_as_category = True\n",
    "    print('\"Credit Card Balance\" shape:', df_credit_card.shape)\n",
    "    df_credit_card, cat_cols = one_hot_encoder(df_credit_card, nan_as_category=True)\n",
    "\n",
    "    # General aggregations\n",
    "    df_credit_card.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = df_credit_card.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = df_credit_card.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    del df_credit_card\n",
    "    gc.collect()\n",
    "\n",
    "    print('\"Credit Card Balance\" final shape:', cc_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55097604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252133, 363)\n",
      "Final shape: (252133, 797)\n"
     ]
    }
   ],
   "source": [
    "df = df_applications.join(df_bureau_agg, how='left', on='SK_ID_CURR')\n",
    "del df_applications, df_bureau_agg\n",
    "print(df.shape)\n",
    "\n",
    "df = df.join(df_previous_agg, how='left', on='SK_ID_CURR')\n",
    "del df_previous_agg\n",
    "\n",
    "df = df.join(pos_agg, how='left', on='SK_ID_CURR')\n",
    "del pos_agg\n",
    "\n",
    "df = df.join(ins_agg, how='left', on='SK_ID_CURR')\n",
    "del ins_agg\n",
    "\n",
    "df = df.join(cc_agg, how='left', on='SK_ID_CURR')\n",
    "del cc_agg\n",
    "\n",
    "print('Final shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bab6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace infinity values by NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed df to a file\n",
    "df.to_csv('df_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8da87",
   "metadata": {},
   "source": [
    "### Traitement des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column \n",
    "def missing_values_table(df):\n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "        \n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "    # Print some summary information\n",
    "    print(\"Your selected dataframe has \" + str(df.shape[1]) +\n",
    "          \" columns. There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values\")\n",
    "        \n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "\n",
    "def missing_values_imputation(df):\n",
    "    for col in df.columns:\n",
    "        med = df[col].median()\n",
    "        df[col].fillna(med, inplace=True)\n",
    "    print(\"Done : 100% \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8daacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Removing empty columns > 50% :\")\n",
    "print(\"=============================\")\n",
    "# removing empty columns > 50%\n",
    "df = df.loc[:, df.isnull().mean() < .50]\n",
    "print(\"Done : 100%\")\n",
    "    \n",
    "# missing_values_imputation\n",
    "print(\"Check missing values before imputation :\")\n",
    "print(\"=======================================\")\n",
    "missing_values_table(df)\n",
    "\n",
    "    \n",
    "print(\"Missing values imputation processing :\")\n",
    "print(\"=====================================\")\n",
    "missing_values_imputation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067f29a",
   "metadata": {},
   "source": [
    "### Affichage déséquilibre des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "y = df['TARGET']\n",
    "X_id = df['SK_ID_CURR']\n",
    "\n",
    "X = df.drop(['TARGET', 'SK_ID_CURR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_hue(plot, feature):\n",
    "    total = len(feature)\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(percentage, (x, y), size=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "pal = {c: 'lime' if c != 1 else 'r' for c in df['TARGET'].unique()}\n",
    "ax = sns.barplot(x=df['TARGET'].value_counts().index,\n",
    "                 y=df['TARGET'].value_counts().values,\n",
    "                 palette=pal)\n",
    "plt.title('Nombre emprunteurs par statut de prêt')\n",
    "plt.xlabel('Valeur de la variable cible', fontsize=20)\n",
    "plt.ylabel('Nombre de personnes', fontsize=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "without_hue(ax, df['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "colors=['lime', 'r']\n",
    "y.value_counts().plot.pie(startangle=90, autopct='%1.1f%%', colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final df to a file\n",
    "df.to_csv('df_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
